{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c6c805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import bm25_weight, tfidf_weight\n",
    "from implicit.bpr import BayesianPersonalizedRanking\n",
    "from implicit.nearest_neighbours import ItemItemRecommender\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightfm\n",
    "import implicit\n",
    "from implicit.nearest_neighbours import ItemItemRecommender, CosineRecommender, TFIDFRecommender, BM25Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f3ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/vkhur/Desktop/Учеба/Рекомендательные системы/Lesson2/webinar_2-20220325T134131Z-001/webinar_2/retail_train.csv')\n",
    "item_features = pd.read_csv('C:/Users/vkhur/Desktop/Учеба/Рекомендательные системы/Lesson2/webinar_2-20220325T134131Z-001/webinar_2/product.csv')\n",
    "user_features = pd.read_csv('C:/Users/vkhur/Desktop/Учеба/Рекомендательные системы/Lesson2/webinar_2-20220325T134131Z-001/webinar_2/hh_demographic.csv')\n",
    "test_df = pd.read_csv('C:/Users/vkhur/Desktop/Учеба/Рекомендательные системы/Lesson2/webinar_2-20220325T134131Z-001/webinar_2/test_users.csv')\n",
    "submit = pd.read_csv('C:/Users/vkhur/Desktop/Учеба/Рекомендательные системы/Lesson2/webinar_2-20220325T134131Z-001/webinar_2/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62ec370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import ItemItemRecommender  # нужен для одного трюка\n",
    "from implicit.nearest_neighbours import bm25_weight, tfidf_weight\n",
    "\n",
    "\n",
    "class MainRecommender:\n",
    "    \"\"\"Рекоммендации, которые можно получить из ALS\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    user_item_matrix: pd.DataFrame\n",
    "        Матрица взаимодействий user-item\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, weighting=True):\n",
    "\n",
    "        # Топ покупок каждого юзера\n",
    "        self.top_purchases = data.groupby(['user_id', 'item_id'])['quantity'].count().reset_index()\n",
    "        self.top_purchases.sort_values('quantity', ascending=False, inplace=True)\n",
    "        self.top_purchases = self.top_purchases[self.top_purchases['item_id'] != 999999]\n",
    "\n",
    "        # Топ покупок по всему датасету\n",
    "        self.overall_top_purchases = data.groupby('item_id')['quantity'].count().reset_index()\n",
    "        self.overall_top_purchases.sort_values('quantity', ascending=False, inplace=True)\n",
    "        self.overall_top_purchases = self.overall_top_purchases[self.overall_top_purchases['item_id'] != 999999]\n",
    "        self.overall_top_purchases = self.overall_top_purchases.item_id.tolist()\n",
    "\n",
    "        self.user_item_matrix = self._prepare_matrix(data)  # pd.DataFrame\n",
    "        self.id_to_itemid, self.id_to_userid, \\\n",
    "            self.itemid_to_id, self.userid_to_id = self._prepare_dicts(self.user_item_matrix)\n",
    "\n",
    "        if weighting:\n",
    "            self.user_item_matrix = bm25_weight(self.user_item_matrix.T).T\n",
    "\n",
    "        self.model = self.fit(self.user_item_matrix)\n",
    "        self.own_recommender = self.fit_own_recommender(self.user_item_matrix)\n",
    "\n",
    "    @staticmethod\n",
    "    def _prepare_matrix(data):\n",
    "        \"\"\"Готовит user-item матрицу\"\"\"\n",
    "        user_item_matrix = pd.pivot_table(data,\n",
    "                                          index='user_id', columns='item_id',\n",
    "                                          values='quantity',  # Можно пробовать другие варианты\n",
    "                                          aggfunc='count',\n",
    "                                          fill_value=0\n",
    "                                          )\n",
    "\n",
    "        user_item_matrix = user_item_matrix.astype(float)  # необходимый тип матрицы для implicit\n",
    "\n",
    "        return user_item_matrix\n",
    "\n",
    "    @staticmethod\n",
    "    def _prepare_dicts(user_item_matrix):\n",
    "        \"\"\"Подготавливает вспомогательные словари\"\"\"\n",
    "\n",
    "        userids = user_item_matrix.index.values\n",
    "        itemids = user_item_matrix.columns.values\n",
    "\n",
    "        matrix_userids = np.arange(len(userids))\n",
    "        matrix_itemids = np.arange(len(itemids))\n",
    "\n",
    "        id_to_itemid = dict(zip(matrix_itemids, itemids))\n",
    "        id_to_userid = dict(zip(matrix_userids, userids))\n",
    "\n",
    "        itemid_to_id = dict(zip(itemids, matrix_itemids))\n",
    "        userid_to_id = dict(zip(userids, matrix_userids))\n",
    "\n",
    "        return id_to_itemid, id_to_userid, itemid_to_id, userid_to_id\n",
    "\n",
    "    @staticmethod\n",
    "    def fit_own_recommender(user_item_matrix):\n",
    "        \"\"\"Обучает модель, которая рекомендует товары, среди товаров, купленных юзером\"\"\"\n",
    "\n",
    "        own_recommender = ItemItemRecommender(K=1, num_threads=4)\n",
    "        own_recommender.fit(csr_matrix(user_item_matrix).T.tocsr())\n",
    "\n",
    "        return own_recommender\n",
    "\n",
    "    @staticmethod\n",
    "    def fit(user_item_matrix, n_factors=50, regularization=0.001, iterations=15, num_threads=4):\n",
    "        \"\"\"Обучает ALS\"\"\"\n",
    "\n",
    "        model = AlternatingLeastSquares(factors=n_factors,\n",
    "                                        regularization=regularization,\n",
    "                                        iterations=iterations,\n",
    "                                        num_threads=num_threads)\n",
    "        model.fit(csr_matrix(user_item_matrix).T.tocsr())\n",
    "\n",
    "        return model\n",
    "\n",
    "    def _update_dict(self, user_id):\n",
    "        \"\"\"Если появился новыю user / item, то нужно обновить словари\"\"\"\n",
    "\n",
    "        if user_id not in self.userid_to_id.keys():\n",
    "\n",
    "            max_id = max(list(self.userid_to_id.values()))\n",
    "            max_id += 1\n",
    "\n",
    "            self.userid_to_id.update({user_id: max_id})\n",
    "            self.id_to_userid.update({max_id: user_id})\n",
    "\n",
    "    def _get_similar_item(self, item_id):\n",
    "        \"\"\"Находит товар, похожий на item_id\"\"\"\n",
    "        recs = self.model.similar_items(self.itemid_to_id[item_id], N=2)  # Товар похож на себя -> рекомендуем 2 товара\n",
    "        top_rec = recs[1][0]  # И берем второй (не товар из аргумента метода)\n",
    "        return self.id_to_itemid[top_rec]\n",
    "\n",
    "    def _extend_with_top_popular(self, recommendations, N=5):\n",
    "        \"\"\"Если кол-во рекоммендаций < N, то дополняем их топ-популярными\"\"\"\n",
    "\n",
    "        if len(recommendations) < N:\n",
    "            recommendations.extend(self.overall_top_purchases[:N])\n",
    "            recommendations = recommendations[:N]\n",
    "\n",
    "        return recommendations\n",
    "\n",
    "    def _get_recommendations(self, user, model, N=5):\n",
    "        \"\"\"Рекомендации через стардартные библиотеки implicit\"\"\"\n",
    "\n",
    "        self._update_dict(user_id=user)\n",
    "        res = [self.id_to_itemid[rec[0]] for rec in model.recommend(userid=self.userid_to_id[user],\n",
    "                                        user_items=csr_matrix(self.user_item_matrix).tocsr(),\n",
    "                                        N=N,\n",
    "                                        filter_already_liked_items=False,\n",
    "                                        filter_items=[self.itemid_to_id[999999]],\n",
    "                                        recalculate_user=True)]\n",
    "\n",
    "        res = self._extend_with_top_popular(res, N=N)\n",
    "\n",
    "        assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "        return res\n",
    "\n",
    "    def get_als_recommendations(self, user, N=5):\n",
    "        \"\"\"Рекомендации через стардартные библиотеки implicit\"\"\"\n",
    "\n",
    "        self._update_dict(user_id=user)\n",
    "        return self._get_recommendations(user, model=self.model, N=N)\n",
    "\n",
    "    def get_own_recommendations(self, user, N=5):\n",
    "        \"\"\"Рекомендуем товары среди тех, которые юзер уже купил\"\"\"\n",
    "\n",
    "        self._update_dict(user_id=user)\n",
    "        return self._get_recommendations(user, model=self.own_recommender, N=N)\n",
    "\n",
    "    def get_similar_items_recommendation(self, user, N=5):\n",
    "        \"\"\"Рекомендуем товары, похожие на топ-N купленных юзером товаров\"\"\"\n",
    "\n",
    "        top_users_purchases = self.top_purchases[self.top_purchases['user_id'] == user].head(N)\n",
    "\n",
    "        res = top_users_purchases['item_id'].apply(lambda x: self._get_similar_item(x)).tolist()\n",
    "        res = self._extend_with_top_popular(res, N=N)\n",
    "\n",
    "        assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "        return res\n",
    "\n",
    "    def get_similar_users_recommendation(self, user, N=5):\n",
    "        \"\"\"Рекомендуем топ-N товаров, среди купленных похожими юзерами\"\"\"\n",
    "\n",
    "        res = []\n",
    "\n",
    "        # Находим топ-N похожих пользователей\n",
    "        similar_users = self.model.similar_users(self.userid_to_id[user], N=N+1)\n",
    "        similar_users = [rec[0] for rec in similar_users]\n",
    "        similar_users = similar_users[1:]   # удалим юзера из запроса\n",
    "\n",
    "        for user in similar_users:\n",
    "            res.extend(self.get_own_recommendations(user, N=1))\n",
    "\n",
    "        res = self._extend_with_top_popular(res, N=N)\n",
    "\n",
    "        assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e59fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefilter_items(data, take_n_popular=5000, item_features=None):\n",
    "    # Уберем самые популярные товары (их и так купят)\n",
    "    popularity = data.groupby('item_id')['user_id'].nunique().reset_index() / data['user_id'].nunique()\n",
    "    popularity.rename(columns={'user_id': 'share_unique_users'}, inplace=True)\n",
    "\n",
    "    top_popular = popularity[popularity['share_unique_users'] > 0.2].item_id.tolist()\n",
    "    data = data[~data['item_id'].isin(top_popular)]\n",
    "\n",
    "    # Уберем самые НЕ популярные товары (их и так НЕ купят)\n",
    "    top_notpopular = popularity[popularity['share_unique_users'] < 0.02].item_id.tolist()\n",
    "    data = data[~data['item_id'].isin(top_notpopular)]\n",
    "\n",
    "    # Уберем не интересные для рекоммендаций категории (department)\n",
    "    if item_features is not None:\n",
    "        department_size = pd.DataFrame(item_features.\\\n",
    "                                        groupby('department')['item_id'].nunique().\\\n",
    "                                        sort_values(ascending=False)).reset_index()\n",
    "\n",
    "        department_size.columns = ['department', 'n_items']\n",
    "        rare_departments = department_size[department_size['n_items'] < 150].department.tolist()\n",
    "        items_in_rare_departments = item_features[item_features['department'].isin(rare_departments)].item_id.unique().tolist()\n",
    "\n",
    "        data = data[~data['item_id'].isin(items_in_rare_departments)]\n",
    "\n",
    "\n",
    "    # Уберем слишком дешевые товары (на них не заработаем). 1 покупка из рассылок стоит 60 руб.\n",
    "    data['price'] = data['sales_value'] / (np.maximum(data['quantity'], 1))\n",
    "    data = data[data['price'] > 2]\n",
    "\n",
    "    # Уберем слишком дорогие товарыs\n",
    "    data = data[data['price'] < 50]\n",
    "\n",
    "    # Возьмем топ по популярности\n",
    "    popularity = data.groupby('item_id')['quantity'].sum().reset_index()\n",
    "    popularity.rename(columns={'quantity': 'n_sold'}, inplace=True)\n",
    "\n",
    "    top = popularity.sort_values('n_sold', ascending=False).head(take_n_popular).item_id.tolist()\n",
    "\n",
    "    # Заведем фиктивный item_id (если юзер покупал товары из топ-5000, то он \"купил\" такой товар)\n",
    "    data.loc[~data['item_id'].isin(top), 'item_id'] = 999999\n",
    "\n",
    "    # ...\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def postfilter(recommendations, item_info, N=5):\n",
    "    \"\"\"Пост-фильтрация товаров\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "    recommendations: list\n",
    "        Ранжированный список item_id для рекомендаций\n",
    "    item_info: pd.DataFrame\n",
    "        Датафрейм с информацией о товарах\n",
    "    \"\"\"\n",
    "\n",
    "    # Уникальность\n",
    "#     recommendations = list(set(recommendations)) - неверно! так теряется порядок\n",
    "    unique_recommendations = []\n",
    "    [unique_recommendations.append(item) for item in recommendations if item not in unique_recommendations]\n",
    "\n",
    "    # Разные категории\n",
    "    categories_used = []\n",
    "    final_recommendations = []\n",
    "\n",
    "    CATEGORY_NAME = 'sub_commodity_desc'\n",
    "    for item in unique_recommendations:\n",
    "        category = item_features.loc[item_features['item_id'] == item, CATEGORY_NAME].values[0]\n",
    "\n",
    "        if category not in categories_used:\n",
    "            final_recommendations.append(item)\n",
    "\n",
    "        unique_recommendations.remove(item)\n",
    "        categories_used.append(category)\n",
    "\n",
    "    n_rec = len(final_recommendations)\n",
    "    if n_rec < N:\n",
    "        final_recommendations.extend(unique_recommendations[:N - n_rec])\n",
    "    else:\n",
    "        final_recommendations = final_recommendations[:N]\n",
    "\n",
    "    assert len(final_recommendations) == N, 'Количество рекомендаций != {}'.format(N)\n",
    "    return final_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b29338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(recommended_list, bought_list, k=5):\n",
    "\n",
    "    bought_list = np.array(bought_list)\n",
    "    recommended_list = np.array(recommended_list)\n",
    "\n",
    "    bought_list = bought_list  # Тут нет [:k] !!\n",
    "    recommended_list = recommended_list[:k]\n",
    "\n",
    "    flags = np.isin(bought_list, recommended_list)\n",
    "\n",
    "    precision = flags.sum() / len(recommended_list)\n",
    "\n",
    "\n",
    "    return precision\n",
    "\n",
    "\n",
    "\n",
    "def ap_k(recommended_list, bought_list, k=5):\n",
    "\n",
    "    bought_list = np.array(bought_list)\n",
    "    recommended_list = np.array(recommended_list)\n",
    "\n",
    "    flags = np.isin(recommended_list, bought_list)\n",
    "\n",
    "    if sum(flags) == 0:\n",
    "        return 0\n",
    "\n",
    "    sum_ = 0\n",
    "    for i in range(1, k+1):\n",
    "\n",
    "        if flags[i - 1] == True:\n",
    "            p_k = precision_at_k(recommended_list, bought_list, k=i)\n",
    "\n",
    "            sum_ += p_k\n",
    "\n",
    "    result = sum_ / min(len(recommended_list), k)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def map_k(recommended_list_list, bought_list_list, k=5):\n",
    "\n",
    "    ap = list()\n",
    "    for i in range(len(recommended_list_list)):\n",
    "        ap.append(ap_k(recommended_list_list[i], bought_list_list[i], k=k))\n",
    "\n",
    "    map_metric = np.mean(ap)\n",
    "\n",
    "    return map_metric\n",
    "\n",
    "def ma_k_var2(predicted, actual, k=5):\n",
    "    return np.mean([ap_k(a,p,k) for a,p in zip(actual, predicted)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c7b856",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "\n",
    "\n",
    "# Важна схема обучения и валидации!\n",
    "# -- давние покупки -- | -- 6 недель -- | -- 3 недель --\n",
    "# подобрать размер 2-ого датасета (6 недель) --> learning curve (зависимость метрики recall@k от размера датасета)\n",
    "val_lvl_1_size_weeks = 6\n",
    "val_lvl_2_size_weeks = 3\n",
    "\n",
    "data_train_lvl_1 = data[data['week_no'] < data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)]\n",
    "data_val_lvl_1 = data[(data['week_no'] >= data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)) &\n",
    "                      (data['week_no'] < data['week_no'].max() - (val_lvl_2_size_weeks))]\n",
    "\n",
    "data_train_lvl_2 = data_val_lvl_1.copy()  # Для наглядности. Далее мы добавим изменения, и они будут отличаться\n",
    "data_val_lvl_2 = data[data['week_no'] >= data['week_no'].max() - val_lvl_2_size_weeks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c9362",
   "metadata": {},
   "outputs": [],
   "source": [
    "users, items, interactions = data.user_id.nunique(), data.item_id.nunique(), data.shape[0]\n",
    "\n",
    "print('# users: ', users) #пользователи\n",
    "print('# items: ', items) #товары\n",
    "print('# interactions: ', interactions) #взаимодействия\n",
    "\n",
    "\n",
    "# Используем train-test split по времени, а не случайно. Возьмем последние 3 недели в качестве теста\n",
    "test_size_weeks = 3\n",
    "\n",
    "data_train = data[data['week_no'] < data['week_no'].max() - test_size_weeks]\n",
    "data_test = data[data['week_no'] >= data['week_no'].max() - test_size_weeks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7236486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export OPENBLAS_NUM_THREADS=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2b5057",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = data_test.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result.columns=['user_id', 'actual']\n",
    "result.head(2)\n",
    "\n",
    "test_users = result.shape[0]\n",
    "new_test_users = len(set(data_test['user_id']) - set(data_train['user_id']))\n",
    "\n",
    "print('В тестовом дата сете {} юзеров'.format(test_users))\n",
    "print('В тестовом дата сете {} новых юзеров'.format(new_test_users))\n",
    "\n",
    "# 1.1 Popularity-based recommendation\n",
    "\n",
    "popularity = data.groupby('item_id')['user_id'].nunique().reset_index() / data['user_id'].nunique()\n",
    "popularity.rename(columns={'user_id': 'share_unique_users'}, inplace=True)\n",
    "\n",
    "top_popular = popularity[popularity['share_unique_users'] > 0.3].item_id.tolist()\n",
    "\n",
    "\n",
    "def popularity_recommendation(data, n=5):\n",
    "    \"\"\"Топ-n популярных товаров\"\"\"\n",
    "\n",
    "    popular = data.groupby('item_id')['sales_value'].sum().reset_index()\n",
    "    popular.sort_values('sales_value', ascending=False, inplace=True)\n",
    "\n",
    "    recs = popular.head(n).item_id\n",
    "\n",
    "    return recs.tolist()\n",
    "\n",
    "\n",
    "\n",
    "# Можно так делать, так как рекомендация не зависит от юзера\n",
    "popular_recs = popularity_recommendation(data_train, n=5)\n",
    "\n",
    "result['popular_recommendation'] = result['user_id'].apply(lambda x: popular_recs)\n",
    "result.head(2)\n",
    "\n",
    "# 1.2. Main Recommender\n",
    "\n",
    "n_items_before = data_train_lvl_1['item_id'].nunique()\n",
    "\n",
    "data_train_lvl_1 = prefilter_items(data_train_lvl_1, item_features=item_features, take_n_popular=5000)\n",
    "\n",
    "n_items_after = data_train_lvl_1['item_id'].nunique()\n",
    "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))\n",
    "\n",
    "recommender = MainRecommender(data_train_lvl_1)\n",
    "\n",
    "recommender.get_als_recommendations(2375, N=5)\n",
    "\n",
    "recommender.get_own_recommendations(2375, N=5)\n",
    "\n",
    "recommender.get_similar_items_recommendation(2375, N=5)\n",
    "\n",
    "recommender.get_similar_users_recommendation(2375, N=5)\n",
    "\n",
    "# В тестовом дата сетеесть \"холодные\" покупатели на которах модель не обучалась\n",
    "# Найдем данные по таким покупателям, для них по умолчанию будем рекомендовать самые популярные товары\n",
    "list_out = result.loc[~result.user_id.isin(data_train_lvl_1.user_id), 'user_id'].tolist()\n",
    "list_out\n",
    "\n",
    "def rule(x, y, model):\n",
    "    if model == 'als':\n",
    "        if x in y:\n",
    "            return list([840361, 1029743, 995242, 981760, 1082185])\n",
    "        else:\n",
    "            return recommender.get_als_recommendations(x, N=5)\n",
    "    elif model == 'own':\n",
    "        if x in y:\n",
    "            return list([840361, 1029743, 995242, 981760, 1082185])\n",
    "        else:\n",
    "            return recommender.get_own_recommendations(x, N=5)\n",
    "    elif model == 'similar_items':\n",
    "        if x in y:\n",
    "            return list([840361, 1029743, 995242, 981760, 1082185])\n",
    "        else:\n",
    "            return recommender.get_similar_items_recommendation(x, N=5)\n",
    "    elif model == 'similar_users':\n",
    "        if x in y:\n",
    "            return list([840361, 1029743, 995242, 981760, 1082185])\n",
    "        else:\n",
    "            return recommender.get_similar_users_recommendation(x, N=5)\n",
    "\n",
    "result['als'] = result['user_id'].apply(lambda x: rule(x, list_out, model='als'))\n",
    "\n",
    "result['own'] = result['user_id'].apply(lambda x: rule(x, list_out, model='own'))\n",
    "\n",
    "result['similar_items'] = result['user_id'].apply(lambda x: rule(x, list_out, model='similar_items'))\n",
    "\n",
    "result.apply(lambda row: precision_at_k(row['als'], row['actual']), axis=1).mean() * 100\n",
    "\n",
    "result.apply(lambda row: precision_at_k(row['own'], row['actual']), axis=1).mean() * 100\n",
    "\n",
    "result.apply(lambda row: precision_at_k(row['similar_items'], row['actual']), axis=1).mean() * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc5a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель 2-ого уровня на выбранных кандидатах\n",
    "\n",
    "# -- давние покупки -- | -- 6 недель -- | -- 3 недель --\n",
    "\n",
    "users_lvl_2 = pd.DataFrame(data_train_lvl_2['user_id'].unique())\n",
    "users_lvl_2.columns = ['user_id']\n",
    "\n",
    "# Пока только warm start\n",
    "train_users = data_train_lvl_1['user_id'].unique()\n",
    "users_lvl_2 = users_lvl_2[users_lvl_2['user_id'].isin(train_users)]\n",
    "\n",
    "users_lvl_2['candidates'] = users_lvl_2['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=50))\n",
    "users_lvl_2.head(2)\n",
    "\n",
    "s = users_lvl_2.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'item_id'\n",
    "\n",
    "users_lvl_2 = users_lvl_2.drop('candidates', axis=1).join(s)\n",
    "users_lvl_2['flag'] = 1\n",
    "\n",
    "users_lvl_2.head(4)\n",
    "\n",
    "targets_lvl_2 = data_train_lvl_2[['user_id', 'item_id']].copy()\n",
    "targets_lvl_2['target'] = 1  # тут только покупки\n",
    "\n",
    "targets_lvl_2 = users_lvl_2.merge(targets_lvl_2, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "targets_lvl_2['target'].fillna(0, inplace= True)\n",
    "targets_lvl_2.drop('flag', axis=1, inplace=True)\n",
    "targets_lvl_2.head(2)\n",
    "\n",
    "df = data_train.groupby('user_id')['item_id'].apply(list).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f25b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заведем фиктивный item_id (если юзер покупал товары из топ-5000, то он \"купил\" такой товар)\n",
    "# data_train.loc[~data_train['item_id'].isin(top_5000), 'item_id'] = 999999\n",
    "\n",
    "user_item_matrix = pd.pivot_table(data_train,\n",
    "                                  index='user_id', columns='item_id',\n",
    "                                  values='quantity',\n",
    "                                  aggfunc='count',\n",
    "                                  fill_value=0\n",
    "                                 )\n",
    "\n",
    "user_item_matrix[user_item_matrix > 0] = 1 # так как в итоге хотим предсказать\n",
    "user_item_matrix = user_item_matrix.astype(float) # необходимый тип матрицы для implicit\n",
    "\n",
    "# переведем в формат saprse matrix\n",
    "sparse_user_item = csr_matrix(user_item_matrix).tocsr()\n",
    "\n",
    "user_item_matrix.head(3)\n",
    "\n",
    "userids = user_item_matrix.index.values\n",
    "itemids = user_item_matrix.columns.values\n",
    "\n",
    "matrix_userids = np.arange(len(userids))\n",
    "matrix_itemids = np.arange(len(itemids))\n",
    "\n",
    "id_to_itemid = dict(zip(matrix_itemids, itemids))\n",
    "id_to_userid = dict(zip(matrix_userids, userids))\n",
    "\n",
    "itemid_to_id = dict(zip(itemids, matrix_itemids))\n",
    "userid_to_id = dict(zip(userids, matrix_userids))\n",
    "\n",
    "\n",
    "\n",
    "model = ItemItemRecommender(K=1, num_threads=4) # K - кол-во ближайших соседей\n",
    "\n",
    "model.fit(csr_matrix(user_item_matrix).T.tocsr(),\n",
    "          show_progress=True)\n",
    "\n",
    "\n",
    "\n",
    "result['own_purchases'] = result['user_id'].\\\n",
    "    apply(lambda x: [id_to_itemid[rec[0]] for rec in\n",
    "                    model.recommend(userid=userid_to_id[x],\n",
    "                                    user_items=sparse_user_item,   # на вход user-item matrix\n",
    "                                    N=5,\n",
    "                                    filter_already_liked_items=False,\n",
    "                                    filter_items=None,\n",
    "                                    recalculate_user=False)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc1e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3. Alternating Least Squares (ALS)\n",
    "\n",
    "def get_recommendations(user, model, N=5):\n",
    "    res = [id_to_itemid[rec[0]] for rec in\n",
    "                    model.recommend(userid=userid_to_id[user],\n",
    "                                    user_items=sparse_user_item,   # на вход user-item matrix\n",
    "                                    N=N,\n",
    "                                    filter_already_liked_items=False,\n",
    "                                    filter_items=None,\n",
    "                                    recalculate_user=True)]\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "model = AlternatingLeastSquares(factors=50,\n",
    "                                regularization=0.001,\n",
    "                                iterations=15,\n",
    "                                calculate_training_loss=True,\n",
    "                                num_threads=4)\n",
    "\n",
    "model.fit(csr_matrix(user_item_matrix).T.tocsr(),  # На вход item-user matrix\n",
    "          show_progress=True)\n",
    "\n",
    "result['als_var'] = result['user_id'].apply(lambda x: get_recommendations(x, model=model, N=5))\n",
    "\n",
    "\n",
    "# 1.3. TF-IDF взвешивание\n",
    "\n",
    "user_item_matrix = tfidf_weight(user_item_matrix.T).T  # Применяется к item-user матрице !\n",
    "\n",
    "\n",
    "model = AlternatingLeastSquares(factors=50,\n",
    "                                regularization=0.001,\n",
    "                                iterations=15,\n",
    "                                calculate_training_loss=True,\n",
    "                                num_threads=4)\n",
    "\n",
    "model.fit(csr_matrix(user_item_matrix).T.tocsr(),  # На вход item-user matrix\n",
    "          show_progress=True)\n",
    "\n",
    "result['als_tfidf'] = result['user_id'].apply(lambda x: get_recommendations(x, model=model, N=5))\n",
    "\n",
    "# 1.4. BM25 взвешивание\n",
    "\n",
    "# Заведем фиктивный item_id (если юзер покупал товары из топ-5000, то он \"купил\" такой товар)\n",
    "# data_train.loc[~data_train['item_id'].isin(top_5000), 'item_id'] = 999999\n",
    "\n",
    "user_item_matrix = pd.pivot_table(data_train,\n",
    "                                  index='user_id', columns='item_id',\n",
    "                                  values='quantity', # Можно пробоват ьдругие варианты\n",
    "                                  aggfunc='count',\n",
    "                                  fill_value=0\n",
    "                                 )\n",
    "\n",
    "user_item_matrix = user_item_matrix.astype(float) # необходимый тип матрицы для implicit\n",
    "\n",
    "# переведем в формат saprse matrix\n",
    "sparse_user_item = csr_matrix(user_item_matrix).tocsr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad910f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = bm25_weight(user_item_matrix.T).T  # Применяется к item-user матрице !\n",
    "\n",
    "\n",
    "\n",
    "model = AlternatingLeastSquares(factors=50,\n",
    "                                regularization=0.001,\n",
    "                                iterations=15,\n",
    "                                calculate_training_loss=True,\n",
    "                                num_threads=4) # K - кол-во билжайших соседей\n",
    "\n",
    "model.fit(csr_matrix(user_item_matrix).T.tocsr(),  # На вход item-user matrix\n",
    "          show_progress=True)\n",
    "\n",
    "result['als_bm25'] = result['user_id'].apply(lambda x: get_recommendations(x, model=model, N=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea3752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.apply(lambda row: precision_at_k(row['popular_recommendation'], row['actual']), axis=1).mean() * 100\n",
    "\n",
    "result.apply(lambda row: precision_at_k(row['own_purchases'], row['actual']), axis=1).mean() * 100\n",
    "\n",
    "result.apply(lambda row: precision_at_k(row['als_var'], row['actual']), axis=1).mean() * 100\n",
    "\n",
    "result.apply(lambda row: precision_at_k(row['als_tfidf'], row['actual']), axis=1).mean() * 100\n",
    "\n",
    "result.apply(lambda row: precision_at_k(row['als_bm25'], row['actual']), axis=1).mean() * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e111ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Измерим качество по MAP@k (Mean Average Precision@k)  - Показывает средневзвешенную точность рекомендаций\n",
    "\n",
    "result.apply(lambda row: ap_k(row['popular_recommendation'], row['actual']), axis=1).mean() * 100\n",
    "\n",
    "result.apply(lambda row: ap_k(row['own_purchases'], row['actual']), axis=1).mean() * 100\n",
    "\n",
    "result.apply(lambda row: ap_k(row['als'], row['actual']), axis=1).mean() * 100\n",
    "\n",
    "result.apply(lambda row: ap_k(row['als_tfidf'], row['actual']), axis=1).mean() * 100\n",
    "\n",
    "result.apply(lambda row: ap_k(row['als_bm25'], row['actual']), axis=1).mean() * 100\n",
    "\n",
    "# 8. Прогнозирование на тестовом датасете\n",
    "\n",
    "#Для удобства перевода данных в подходящий для загрузки формат:\n",
    "\n",
    "def transform_data_for_eval(dataset, rec_col, user_col='user_id'):\n",
    "    '''\n",
    "    Func for transforming recommendations into kaggle evaluation format\n",
    "\n",
    "    Parameters:\n",
    "    dataset (pd.DataFrame): Dataset with 2 required columns:\n",
    "        rec_col - column with recommendations should be iterable\n",
    "        user_col - columns with user id\n",
    "\n",
    "    rec_col (str): name of column in dataset with recommendations\n",
    "\n",
    "    user_col (str): name of column in dataset with user id\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame in suitable format\n",
    "\n",
    "   '''\n",
    "    eval_dataset = dataset[[user_col, rec_col]].copy()\n",
    "    eval_dataset[rec_col] = eval_dataset[rec_col].apply(lambda x: ' '.join([str(i) for i in x]))\n",
    "    eval_dataset.rename(columns={\n",
    "        user_col: 'UserId',\n",
    "        rec_col: 'Predicted'\n",
    "    }, inplace=True)\n",
    "    return eval_dataset\n",
    "\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f818a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эффективней других оказалась идея найти 1 ближашего соседа и фильтровать по топ 5000, ее и применим.\n",
    "\n",
    "def get_recommendations(user, model, N=5):\n",
    "    res = [id_to_itemid[rec[0]] for rec in\n",
    "                    model.recommend(userid=userid_to_id[user],\n",
    "                                    user_items=sparse_user_item,   # на вход user-item matrix\n",
    "                                    N=N,\n",
    "                                    filter_already_liked_items=False,\n",
    "                                    filter_items=None,\n",
    "                                    recalculate_user=True)]\n",
    "    return res\n",
    "\n",
    "user_item_matrix = pd.pivot_table(data_train,\n",
    "                                  index='user_id', columns='item_id',\n",
    "                                  values='quantity',\n",
    "                                  aggfunc='count',\n",
    "                                  fill_value=0\n",
    "                                 )\n",
    "\n",
    "user_item_matrix[user_item_matrix > 0] = 1 # так как в итоге хотим предсказать\n",
    "user_item_matrix = user_item_matrix.astype(float) # необходимый тип матрицы для implicit\n",
    "\n",
    "# переведем в формат saprse matrix\n",
    "sparse_user_item = csr_matrix(user_item_matrix).tocsr()\n",
    "\n",
    "userids = user_item_matrix.index.values\n",
    "itemids = user_item_matrix.columns.values\n",
    "\n",
    "matrix_userids = np.arange(len(userids))\n",
    "matrix_itemids = np.arange(len(itemids))\n",
    "\n",
    "id_to_itemid = dict(zip(matrix_itemids, itemids))\n",
    "id_to_userid = dict(zip(matrix_userids, userids))\n",
    "\n",
    "itemid_to_id = dict(zip(itemids, matrix_itemids))\n",
    "userid_to_id = dict(zip(userids, matrix_userids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb82c32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = ItemItemRecommender(K=1, num_threads=4) # K - кол-во ближайших соседей\n",
    "\n",
    "model.fit(csr_matrix(user_item_matrix).T.tocsr(),\n",
    "          show_progress=True)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4834bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_out = test_df.loc[~test_df.user_id.isin(data_train.user_id), 'user_id'].tolist()\n",
    "\n",
    "def rule(x, y):\n",
    "    if x in y:\n",
    "         return list([840361, 1029743, 995242, 981760, 1082185])\n",
    "    else:\n",
    "         return get_recommendations(x, model=model, N=5)\n",
    "\n",
    "test_df['own_purchases'] = test_df['user_id'].apply(lambda x: rule(x, list_out))\n",
    "\n",
    "sampl_df = transform_data_for_eval(test_df, rec_col='own_purchases', user_col='user_id')\n",
    "\n",
    "sampl_df.to_csv('sample_test_submission.csv', index=False)\n",
    "\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47c70f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampl_df.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
