{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMBdGcvjC4Ji"
   },
   "source": [
    "# Вебинар 6. Двухуровневые модели рекомендаций\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Jgaacz0C4Jl"
   },
   "source": [
    "Код для src, utils, metrics вы можете скачать из [этого](https://github.com/geangohn/recsys-tutorial) github репозитория"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Aur99NsC4Jm",
    "outputId": "9b9a338b-a52f-4253-9694-ac431b62eefc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit import als\n",
    "\n",
    "# Модель второго уровня\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Написанные нами функции\n",
    "from src.metrics import precision_at_k, recall_at_k\n",
    "from src.utils import prefilter_items\n",
    "from src.recommenders import MainRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vso_erSdC4Jo",
    "outputId": "da20dbf1-3086-4fd6-ac92-f7653d7f9f71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1004906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1033142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     2375  26984851472    1  1004906         1         1.39       364   \n",
       "1     2375  26984851472    1  1033142         1         0.82       364   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0         -0.6        1631        1          0.0                0.0  \n",
       "1          0.0        1631        1          0.0                0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/vkhur/Desktop/Учеба/Рекомендательные системы/Lesson2/webinar_2-20220325T134131Z-001/webinar_2/retail_train.csv')\n",
    "item_features = pd.read_csv('C:/Users/vkhur/Desktop/Учеба/Рекомендательные системы/Lesson2/webinar_2-20220325T134131Z-001/webinar_2/product.csv')\n",
    "user_features = pd.read_csv('C:/Users/vkhur/Desktop/Учеба/Рекомендательные системы/Lesson2/webinar_2-20220325T134131Z-001/webinar_2/hh_demographic.csv')\n",
    "\n",
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "\n",
    "\n",
    "# Важна схема обучения и валидации!\n",
    "# -- давние покупки -- | -- 6 недель -- | -- 3 недель -- \n",
    "# подобрать размер 2-ого датасета (6 недель) --> learning curve (зависимость метрики recall@k от размера датасета)\n",
    "val_lvl_1_size_weeks = 6\n",
    "val_lvl_2_size_weeks = 3\n",
    "\n",
    "data_train_lvl_1 = data[data['week_no'] < data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)]\n",
    "data_val_lvl_1 = data[(data['week_no'] >= data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)) &\n",
    "                      (data['week_no'] < data['week_no'].max() - (val_lvl_2_size_weeks))]\n",
    "\n",
    "data_train_lvl_2 = data_val_lvl_1.copy()  # Для наглядности. Далее мы добавим изменения, и они будут отличаться\n",
    "data_val_lvl_2 = data[data['week_no'] >= data['week_no'].max() - val_lvl_2_size_weeks]\n",
    "\n",
    "data_train_lvl_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zcnV3l4XC4Jp",
    "outputId": "d58f889c-0671-4bb9-b2b6-2dc2e8c24fce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decreased # items from 83685 to 5001\n"
     ]
    }
   ],
   "source": [
    "n_items_before = data_train_lvl_1['item_id'].nunique()\n",
    "\n",
    "data_train_lvl_1 = prefilter_items(data_train_lvl_1, item_features=item_features, take_n_popular=5000)\n",
    "\n",
    "n_items_after = data_train_lvl_1['item_id'].nunique()\n",
    "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "729d4287bb794971802d9da5e141f10a",
      "32375ef613474af6a0fcadb9255eb835"
     ]
    },
    "id": "zgYXRQ0lC4Jq",
    "outputId": "d9ea41ae-3b4d-41b4-fc46-90868ebb9894"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729d4287bb794971802d9da5e141f10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32375ef613474af6a0fcadb9255eb835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5001.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recommender = MainRecommender(data_train_lvl_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xB9JX5swC4Jr",
    "outputId": "af05502b-1fb9-42b6-919c-b915ac3a0106"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[899624, 1106523, 1044078, 871756, 844179]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_als_recommendations(2375, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNVa6jWLC4Jr",
    "outputId": "c69395e4-8171-41f1-c0c4-067b582f26e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[948640, 918046, 847962, 907099, 873980]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_own_recommendations(2375, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0NoB_lSJC4Js",
    "outputId": "9f91a42c-08bf-4037-fca1-54db5a5cafee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1046545, 1044078, 1044078, 1078652, 1018809]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_similar_items_recommendation(2375, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GdQO5CWKC4Js",
    "outputId": "08936fbf-715f-412a-9fbe-065816bb6a90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1101502, 979674, 10457044, 974265, 959455]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_similar_users_recommendation(2375, N=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bqs9Sw_YC4Jt"
   },
   "source": [
    "### Задание 1\n",
    "\n",
    "A) Попробуйте различные варианты генерации кандидатов. Какие из них дают наибольший recall@k ?\n",
    "- Пока пробуем отобрать 50 кандидатов (k=50)\n",
    "- Качество измеряем на data_val_lvl_1: следующие 6 недель после трейна\n",
    "\n",
    "Дают ли own recommendtions + top-popular лучший recall?  \n",
    "\n",
    "B)* Как зависит recall@k от k? Постройте для одной схемы генерации кандидатов эту зависимость для k = {20, 50, 100, 200, 500}  \n",
    "C)* Исходя из прошлого вопроса, как вы думаете, какое значение k является наиболее разумным?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frt2RzDWC4Jt",
    "outputId": "7c594abf-4a34-406b-9897-8bfbddf69a93"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[853529, 865456, 867607, 872137, 874905, 87524...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[15830248, 838136, 839656, 861272, 866211, 870...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                             actual\n",
       "0        1  [853529, 865456, 867607, 872137, 874905, 87524...\n",
       "1        2  [15830248, 838136, 839656, 861272, 866211, 870..."
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lvl_1 = data_val_lvl_1.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result_lvl_1.columns=['user_id', 'actual']\n",
    "result_lvl_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xM5W4mU4C4Jt"
   },
   "outputs": [],
   "source": [
    "# your_code\n",
    "\n",
    "N = 200\n",
    "hot_users = data_train_lvl_1['user_id'].unique().tolist()\n",
    "top_popular = recommender.overall_top_purchases[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "result_lvl_1['als'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_als_recommendations(x, N=N) if x in hot_users else top_popular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "result_lvl_1['self'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=N) if x in hot_users else top_popular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "result_lvl_1['similar_items'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_similar_items_recommendation(x, N=N) if x in hot_users else top_popular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lvl_1['combined'] = result_lvl_1['user_id'].apply(lambda x: \\\n",
    "    result_lvl_1.loc[result_lvl_1.user_id == x]['als'].tolist()[0][0:66] + \\\n",
    "    result_lvl_1.loc[result_lvl_1.user_id == x]['self'].tolist()[0][0:67] + \\\n",
    "    result_lvl_1.loc[result_lvl_1.user_id == x]['similar_items'].tolist()[0][0:67])\n",
    "\n",
    "result_lvl_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_recall_at_k(recommended_matrix, bought_matrix, k=5):\n",
    "    \n",
    "    rows_count = bought_matrix.shape[0]\n",
    "    recall_by_row = [recall_at_k(recommended_matrix[i], bought_matrix[i], k) for i in range(rows_count)]\n",
    "    recall_mean = np.mean(recall_by_row)\n",
    "\n",
    "    return recall_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = result_lvl_1.columns.drop(['user_id', 'actual'])\n",
    "\n",
    "for column in columns:\n",
    "    recall_mean = average_recall_at_k(result_lvl_1[column], result_lvl_1.actual, k=200)\n",
    "    print('{:35} {:.4f} %'.format(column, recall_mean * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучший результат дает сочетание рекомендации собственных покупок и топ популярных покупок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Перебираемые значения K.\n",
    "k_list = [20, 50, 100, 200, 300, 400, 500]\n",
    "\n",
    "# Список для сохранения результатов.\n",
    "recall_list = [] # \n",
    "\n",
    "# Список пользователей.\n",
    "users_list = result_lvl_1['user_id'].values\n",
    "\n",
    "for k in k_list:\n",
    "    own_recs = []\n",
    "    for user in users_list: \n",
    "        own_recs.append(recommender.get_own_recommendations(user, N=k) if x in hot_users else top_popular)\n",
    "    recall_list.append(average_recall_at_k(own_recs, result_lvl_1.actual, k=k))\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(k_list, recall_list, label=\"Own recommendation\")\n",
    "plt.xlabel('k-items')\n",
    "plt.ylabel('recall@k')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значение метрики перестает расти, если K>200. Скорее всего это связано с тем что в среднем из валидационного датасета пользователи покупают 12 товаров. При K>200 все купленные товары попадают в число рекомендованных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(data_val_lvl_1.item_id.values).size / np.unique(data_val_lvl_1.user_id.values).size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAHJu3Z5C4Ju"
   },
   "source": [
    "### Задание 2.\n",
    "\n",
    "Обучите модель 2-ого уровня, при этом:\n",
    "    - Добавьте минимум по 2 фичи для юзера, товара и пары юзер-товар\n",
    "    - Измерьте отдельно precision@5 модели 1-ого уровня и двухуровневой модели на data_val_lvl_2\n",
    "    - Вырос ли precision@5 при использовании двухуровневой модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZQcrch7C4Ju"
   },
   "outputs": [],
   "source": [
    "# your_code\n",
    "users_lvl_2 = pd.DataFrame(data_train_lvl_2['user_id'].unique())\n",
    "users_lvl_2.columns = ['user_id']\n",
    "\n",
    "# Пока только warm start\n",
    "train_users = data_train_lvl_1['user_id'].unique()\n",
    "users_lvl_2 = users_lvl_2[users_lvl_2['user_id'].isin(train_users)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_lvl_2 = pd.DataFrame(data_train_lvl_2['user_id'].unique())\n",
    "users_lvl_2.columns = ['user_id']\n",
    "model_rec = recommender.get_model_recommendation(N=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_lvl_2 = users_lvl_2.merge(model_rec,\n",
    "                                on='user_id',\n",
    "                                how='inner')\n",
    "\n",
    "users_lvl_2.columns = ['user_id', 'candidates']\n",
    "users_lvl_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = users_lvl_2.apply(lambda x: pd.Series(x['candidates']), axis=1)\\\n",
    "    .stack().reset_index(level=1, drop=True)\n",
    "\n",
    "s.name = 'item_id'\n",
    "\n",
    "users_lvl_2 = users_lvl_2.drop('candidates', axis=1).join(s)\n",
    "users_lvl_2['flag'] = 1\n",
    "\n",
    "users_lvl_2.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_lvl_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_lvl_2 = data_train_lvl_2[['user_id', 'item_id', 'quantity', 'sales_value', 'store_id', 'week_no']].copy()\n",
    "targets_lvl_2['target'] = 1  # тут только покупки \n",
    "\n",
    "targets_lvl_2 = users_lvl_2.merge(targets_lvl_2, on=['user_id', 'item_id'], how='left')\n",
    "\n",
    "targets_lvl_2['target'].fillna(0, inplace= True)\n",
    "targets_lvl_2.drop('flag', axis=1, inplace=True)\n",
    "\n",
    "targets_lvl_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_lvl_2 = targets_lvl_2.merge(item_features, on='item_id', how='left')\n",
    "targets_lvl_2 = targets_lvl_2.merge(user_features, on='user_id', how='left')\n",
    "\n",
    "targets_lvl_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_lvl_2['quantity'].fillna(targets_lvl_2['quantity'].median(),\n",
    "                                 inplace=True)\n",
    "targets_lvl_2['sales_value'].fillna(targets_lvl_2['sales_value'].mean(),\n",
    "                                    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mode_func_series(x, mode_store):\n",
    "    x = pd.Series.mode(x)\n",
    "    if type(x) != float:\n",
    "        if len(x) >= 1:\n",
    "            x = x[0]\n",
    "        else:\n",
    "            x = mode_store\n",
    "    return x\n",
    "\n",
    "mode_store = pd.Series.mode(targets_lvl_2['store_id']).values[0]\n",
    "\n",
    "df = \\\n",
    "    targets_lvl_2.groupby(by='user_id')['store_id']\\\n",
    "        .agg(lambda x: calc_mode_func_series(x, mode_store)).reset_index()\n",
    "\n",
    "df.rename(columns={'store_id': 'mode_store_user'},\n",
    "          inplace=True)\n",
    "\n",
    "targets_lvl_2 = targets_lvl_2.merge(df, \n",
    "                                    on='user_id',\n",
    "                                    how='inner')\n",
    "\n",
    "targets_lvl_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.pivot_table(targets_lvl_2,\n",
    "                    index='item_id', columns='week_no',\n",
    "                    values='quantity',\n",
    "                    aggfunc='count',\n",
    "                    fill_value=0\n",
    "                    )\n",
    "\n",
    "df = df.agg('median', axis='columns').reset_index()\n",
    "df.columns = ['item_id', 'quantatity_of_item_per_week']\n",
    "\n",
    "targets_lvl_2 = targets_lvl_2.merge(df,\n",
    "                                    on='item_id',\n",
    "                                    how='inner')\n",
    "\n",
    "targets_lvl_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.pivot_table(targets_lvl_2,\n",
    "                    index='department', columns='week_no',\n",
    "                    values='quantity',\n",
    "                    aggfunc='count',\n",
    "                    fill_value=0\n",
    "                    )\n",
    "\n",
    "df = df.agg('median', axis='columns').reset_index()\n",
    "df.columns = ['department', 'quantatity_of_item_in_category_per_week']\n",
    "\n",
    "targets_lvl_2 = targets_lvl_2.merge(df,\n",
    "                                    on='department',\n",
    "                                    how='inner')\n",
    "targets_lvl_2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.pivot_table(targets_lvl_2,\n",
    "                    index='user_id', columns='department',\n",
    "                    values='quantity',\n",
    "                    aggfunc='count',\n",
    "                    fill_value=0\n",
    "                    )\n",
    "\n",
    "df = df.idxmax(axis=1).reset_index()\n",
    "df.columns = ['user_id', 'top_department']\n",
    "\n",
    "targets_lvl_2 = targets_lvl_2.merge(df,\n",
    "                                    on='user_id',\n",
    "                                    how='inner'\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.pivot_table(targets_lvl_2,\n",
    "                    index='user_id', columns='brand',\n",
    "                    values='quantity',\n",
    "                    aggfunc='count',\n",
    "                    fill_value=0\n",
    "                    )\n",
    "\n",
    "df = df.idxmax(axis=1).reset_index()\n",
    "df.columns = ['user_id', 'top_brand']\n",
    "\n",
    "targets_lvl_2 = targets_lvl_2.merge(df,\n",
    "                                    on='user_id',\n",
    "                                    how='inner'\n",
    "                                    )\n",
    "\n",
    "df = pd.pivot_table(targets_lvl_2,\n",
    "                    index='user_id', columns='department',\n",
    "                    values='sales_value',\n",
    "                    aggfunc='mean',\n",
    "                    fill_value=0\n",
    "                    )\n",
    "\n",
    "df = pd.pivot_table(targets_lvl_2,\n",
    "                    index='user_id', columns='department',\n",
    "                    values='sales_value',\n",
    "                    aggfunc='mean',\n",
    "                    fill_value=0\n",
    "                    )\n",
    "\n",
    "df = df.stack().reset_index()\n",
    "df.columns = ['user_id', 'department', 'mean_sales_value_of_user_in_department']\n",
    "\n",
    "targets_lvl_2 = targets_lvl_2.merge(df,\n",
    "                                    on=['user_id', 'department'],\n",
    "                                    how='inner')\n",
    "\n",
    "df = \\\n",
    "    targets_lvl_2.groupby(by=['user_id'])['age_desc']\\\n",
    "    .apply(lambda x: pd.Series.mode(x))\n",
    "df = df.reset_index()\n",
    "df.drop(columns='level_1',\n",
    "        inplace=True)\n",
    "\n",
    "df.columns=['user_id', 'age_desc_corrected']\n",
    "\n",
    "targets_lvl_2 = targets_lvl_2.merge(df,\n",
    "                                    on='user_id',\n",
    "                                    how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = \\\n",
    "    ['user_id', \n",
    "     'item_id', \n",
    "     'quantity', \n",
    "     'sales_value', \n",
    "     'store_id',\n",
    "     'department',\n",
    "     'manufacturer',\n",
    "     'age_desc_corrected', \n",
    "     'brand',\n",
    "     'mode_store_user',\n",
    "     'quantatity_of_item_per_week',\n",
    "     'quantatity_of_item_in_category_per_week', \n",
    "     'top_department',\n",
    "     'top_brand', \n",
    "     'mean_sales_value_of_user_in_department'\n",
    "    ]\n",
    "\n",
    "targets_lvl_2['store_id'].fillna(mode_store, inplace=True)\n",
    "targets_lvl_2[feature_columns].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = targets_lvl_2[feature_columns]\n",
    "y_train = targets_lvl_2['target']\n",
    "X_train[['store_id', 'mode_store_user']] = \\\n",
    "    X_train[['store_id', 'mode_store_user']].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = ['user_id', 'item_id', \n",
    "             'store_id', 'manufacturer', 'age_desc_corrected', 'department', \n",
    "             'brand', 'mode_store_user',\n",
    "             'top_department', 'top_brand']\n",
    "\n",
    "X_train[cat_feats] = X_train[cat_feats].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "model = CatBoostClassifier(\n",
    "    random_seed=55,\n",
    "    iterations=100,\n",
    "    learning_rate=0.1)\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=cat_feats,\n",
    "    verbose=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = model.predict(X_train)\n",
    "train_preds = train_preds.astype(bool)\n",
    "\n",
    "rec_items = X_train[train_preds].groupby(by=['user_id'])['item_id'].unique().reset_index()\n",
    "rec_items.columns = ['user_id', 'model_preds']\n",
    "\n",
    "rec_items['model_preds'] = \\\n",
    "    rec_items['model_preds'].apply(lambda x: x[:10] if len(x) >= 10 else x)\n",
    "\n",
    "result_lvl_2 = data_val_lvl_2.groupby('user_id')['item_id'].unique().reset_index()\n",
    "result_lvl_2.columns = ['user_id', 'actual']\n",
    "result_lvl_2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_lvl_2 = result_lvl_2.merge(rec_items,\n",
    "                                  on='user_id',\n",
    "                                  how='inner')\n",
    "\n",
    "result_lvl_2.apply(lambda row: precision_at_k(row['model_preds'], row['actual']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9FLlIq15C4Ju"
   },
   "source": [
    "### Финальный проект\n",
    "\n",
    "Мы уже прошли всю необходимуб теорию для финального проекта. Проект осуществляется на данных из вебинара (данные считаны в начале ДЗ).\n",
    "Рекомендуем вам **начать делать проект сразу после этого домашнего задания**\n",
    "- Целевая метрика - precision@5. Порог для уcпешной сдачи проекта precision@5 > 25%\n",
    "- Будет public тестовый датасет, на котором вы сможете измерять метрику\n",
    "- Также будет private тестовый датасет для измерения финального качества\n",
    "- НЕ обязательно, но крайне желательно использовать 2-ух уровневые рекоммендательные системы в проекте\n",
    "- Вы сдаете код проекта в виде github репозитория и csv файл с рекомендациями "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw_webinar_6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
